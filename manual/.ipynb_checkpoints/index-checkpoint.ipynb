{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['base/js/utils'],\n",
       "function(utils) {\n",
       "   utils.load_extensions('calico-spell-check');\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require(['base/js/utils'],\n",
    "function(utils) {\n",
    "   utils.load_extensions('calico-spell-check');\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPyOpt: The tool for Bayesian Optimization \n",
    "\n",
    "### Written by Javier Gonzalez (j.h.gonzalez@sheffield.ac.uk), University of Sheffield.\n",
    "\n",
    "## Reference Manual index\n",
    "\n",
    "*Last updated Friday, 11 March 2016.*\n",
    "\n",
    "=====================================================================================================\n",
    "\n",
    "1. **What is GPyOpt?**\n",
    "\n",
    "2. **Installation and setup**\n",
    "\n",
    "3. **First steps with GPyOpt and Bayesian Optimization**\n",
    "\n",
    "4. **Alternative interfaces**\n",
    "\n",
    "5. **What options are available in GPyOpt?**\n",
    "    1. Bayesian optmization with restrictions.\n",
    "    2. Batch Bayesian optimization.\n",
    "    3. Mixing different types of variables.\n",
    "    4. Armed bandits problems.\n",
    "    5. Integrating the model hyperparameters.\n",
    "    6. Available models.\n",
    "\n",
    "=====================================================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is GPyOpt?\n",
    "\n",
    "[GPyOpt](http://sheffieldml.github.io/GPy/) is a tool for optimization (minimization) of black-box functions using Gaussian processes. It has been implemented in [Python](https://www.python.org/download/releases/2.7/) by the [group of Machine Learning](http://ml.dcs.shef.ac.uk/sitran/) (at SITraN) of the University of Sheffield. \n",
    "\n",
    "GPyOpt is based on [GPy](https://github.com/SheffieldML/GPy), a library for Gaussian process modeling in Python. [Here](http://nbviewer.ipython.org/github/SheffieldML/notebook/blob/master/GPy/index.ipynb) you can also find some notebooks about GPy functionalities. GPyOpt is a tool for Bayesian Optimization but we also use it for academic dissemination in [Gaussian Processes Summer Schools](gpss.cc), where you can find some extra labs and a variety of talks on Gaussian processes and Bayesian optimization.\n",
    "\n",
    "The purpose of this manual is to provide a guide to use GPyOpt. The framework is [BSD-3 licensed](https://opensource.org/licenses/BSD-3-Clause) and we welcome collaborators to develop new functionalities. If you have any question or suggestions about the notebooks, please contact (Javier Gonzalez) j.h.gonzalez@sheffield.ac.uk. For general questions about the package please write an issue in the [GitHub repository](https://github.com/SheffieldML/GPyOpt).\n",
    "\n",
    "<img src=\"./files/figures/gpyopt.jpeg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to install GPyOpt is using pip. Ubuntu users can do:\n",
    "\n",
    "```\n",
    "sudo apt-get install python-pip\n",
    "pip install gpyopt\n",
    "```\n",
    "\n",
    "If you'd like to install from source, or want to contribute to the project (e.g. by sending pull requests via github), read on. Clone the repository in GitHub and add it to your $PYTHONPATH.\n",
    "\n",
    "\n",
    "```\n",
    "git clone git@github.com:SheffieldML/GPyOpt.git ~/SheffieldML\n",
    "echo 'PYTHONPATH=$PYTHONPATH:~/SheffieldML' >> ~/.bashrc\n",
    "```\n",
    "\n",
    "There are a number of dependencies that you may need to install. Three of them are needed to ensure the good behaviour of the package. These are, GPy, numpy and scipy. Other dependencies, such as DIRECT, cma and pyDOE are optional and only are required for in some options of the module. All of them are pip installable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. First steps with GPyOpt and Bayesian Optimization\n",
    "\n",
    "The tutorial [Introduction to Bayesian Optimization with GPyOpt](./GPyOpt_reference_manual.ipynb) reviews some basic concepts on Bayesian optimization and shows some basic GPyOpt functionalities. It is a manual for beginners who want to start using the package.\n",
    "\n",
    "<img src=\"./files/figures/iteration001.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Alternative GPyOpt interfaces:  Modular Bayesian optimization and Spearmint\n",
    "\n",
    "GPyOpt has different interfaces oriented to different types of users. Apart from the general interface (detailed in the introductory manual) you can use GPyOpt in a modular way: you can implement and use your some elements of the optimization process, such us a new model or acquisition function, but still use the main backbone of the package. You can check the [GPyOpt: Modular Bayesian Optimization](./GPyOpt_modular_bayesian_optimization.ipynb) notebook if you are interested on using GPyOpt this way. \n",
    "\n",
    "Also, we have developed and GPyOpt interface with Spearmint. This means that if you use Spearmint you can re-run your experiments with GPyOpt by changing only one line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimization options available in GPyOpt\n",
    "\n",
    "There are several options implemented in GPyOpt that allows to cover a wide range of specific optimization problems. We have implemented a collection of notebooks to explain these functionalities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Bayesian optmization with restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With GPyOpt you can solve optimization problems with arbitrary non trivial restrictions. Have a look to the notebook [GPyOpt: Bayesian Optimization with fixed constrains](./GPyOpt_constrained_optimization.ipynb) if you want to know more about how to use GPyOpt in these type of problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Batch Bayesian optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5.3 Mixing different types of variables.\n",
    "In GPyOpt you can easily combine different types of variables in the optimization. Currently you can use discrete an continuous variables. The way GPyOpt handles discrete variables is by marginally optimizing the acquisition functions over combinations of feasible values. This may slow down the optimization if many discrete variables are used but it avoids rounding errors. See the notebook entitled [GPyOpt: mixing different types of variables](./GPyOpt_mixed_domain.ipynb) for further details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Armed bandits problems\n",
    "\n",
    "Armed bandits optimization problems are a particular case of Bayesian Optimization that appear when the domain of the function to optimize is entirely discrete. This makes has several advantages with respect to optimize in continuous domains. The most remarkable is that the optimization of the acquisition function can be done by taking the $arg min$ of all candidate points while the rest of the BO theory applies. In the notebook [GPyOpt: armed bandits optimization](/.GPyOpt_bandits_optimization.ipynb) you can check how to use GPyOpt in these types of problems.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Using various cost evaluation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Integrating the model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Available models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Objective functions benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
